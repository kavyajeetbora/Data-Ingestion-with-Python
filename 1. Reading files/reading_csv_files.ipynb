{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import bz2\n",
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the file using csv module\n",
    "\n",
    "Here we will read an archive file which is a TAR archive file called bz2 file.\n",
    "\n",
    "**What Are File Archives ?**:\n",
    "\n",
    "File compression tools (often called file archivers) like 7-Zip and PeaZip are able to compress one or more files and/or folders to a single file with just one file extension. This makes it much easier to store all of that content in one place or to share multiple files with someone.\n",
    "\n",
    "The top three most common archive file types are ZIP, RAR, and 7Z\n",
    "\n",
    "**bz2 file** is a TAR archive, compressed with a Burrows-Wheeler (BZ2) compression algorithm, along with Run-Length Encoding (RLE) for better compression. Most commonly, this file format is used for distributing software packages on Unix based operating systems like Linux.\n",
    "\n",
    "With the help of python library, bz2 we will read the data file in \"rt\" mode (to read a file as text).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VendorID': '2', 'tpep_pickup_datetime': '2018-10-31 07:10:55', 'tpep_dropoff_datetime': '2018-11-01 06:43:24', 'passenger_count': '1', 'trip_distance': '2.57', 'RatecodeID': '1', 'store_and_fwd_flag': 'N', 'PULocationID': '211', 'DOLocationID': '48', 'payment_type': '1', 'fare_amount': '14.5', 'extra': '0.5', 'mta_tax': '0.5', 'tip_amount': '4.74', 'tolls_amount': '0.0', 'improvement_surcharge': '0.3', 'total_amount': '20.54'}\n"
     ]
    }
   ],
   "source": [
    "fileLocation = \"C:\\\\Users\\\\KVBA\\\\OneDrive - Ramboll\\\\Documents\\\\Literature\\\\Tutorials\\\\data ingestion with python\\\\Exercise Files\\Ch02\\\\02_01\\\\taxi.csv.bz2\"\n",
    "with bz2.open(fileLocation, \"rt\") as bz2_file:\n",
    "    reader = csv.DictReader(bz2_file)\n",
    "\n",
    "    for csv_record in reader:\n",
    "        print(csv_record)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This the format of the data stored. We need to define the colums because in csv file the data type is only text. We need to tell the datatypes for each columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Column = namedtuple(\"Column\", \"src dest convert\")\n",
    "\n",
    "def parse_datetime(text):\n",
    "    return datetime.strptime(text, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "columns = [\n",
    "    Column(\"VendorID\", \"vendor_id\", int),\n",
    "    Column(\"passenger_count\", \"num_passengers\", int),\n",
    "    Column(\"tip_amount\", \"tip\", float),\n",
    "    Column(\"total_amount\", \"price\", float),\n",
    "    Column(\"tpep_dropoff_datetime\", \"drop_time\", parse_datetime),\n",
    "    Column(\"tpep_pickup_datetime\", \"pickup_time\", parse_datetime),\n",
    "    Column(\"trip_distance\", \"distance\", float)\n",
    "]\n",
    "\n",
    "def iter_records(file_name):\n",
    "    with bz2.open(file_name, \"rt\") as bz2_file:\n",
    "        reader = csv.DictReader(bz2_file)\n",
    "        for csv_record in reader:\n",
    "            record = {}\n",
    "            for col in columns:\n",
    "                value = csv_record[col.src]\n",
    "                record[col.dest] = col.convert(value)\n",
    "            yield record\n",
    "\n",
    "\n",
    "def example(nrows=3):\n",
    "    for i, record in enumerate(iter_records(fileLocation)):\n",
    "        if i>nrows:\n",
    "            break\n",
    "        pprint(record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have used namedtuple which is nothing but:\n",
    "\n",
    "```python\n",
    "## Define the tuple defination\n",
    "Column = namedtuple(\"Column\", \"src dest convert\")\n",
    "\n",
    "## Create an instance:\n",
    "Column(\"Vendor ID\", \"vendor_id\", int)\n",
    "```\n",
    "Stores the tuple as shown below:\n",
    "```python\n",
    "Column(src='Vendor ID', dest='vendor_id', convert=<class 'int'>)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'distance': 2.57,\n",
      " 'drop_time': datetime.datetime(2018, 11, 1, 6, 43, 24),\n",
      " 'num_passengers': 1,\n",
      " 'pickup_time': datetime.datetime(2018, 10, 31, 7, 10, 55),\n",
      " 'price': 20.54,\n",
      " 'tip': 4.74,\n",
      " 'vendor_id': 2}\n",
      "{'distance': 3.58,\n",
      " 'drop_time': datetime.datetime(2018, 10, 31, 16, 50, 10),\n",
      " 'num_passengers': 5,\n",
      " 'pickup_time': datetime.datetime(2018, 10, 31, 16, 38, 25),\n",
      " 'price': 13.8,\n",
      " 'tip': 0.0,\n",
      " 'vendor_id': 2}\n",
      "{'distance': 2.39,\n",
      " 'drop_time': datetime.datetime(2018, 10, 31, 20, 31, 47),\n",
      " 'num_passengers': 1,\n",
      " 'pickup_time': datetime.datetime(2018, 10, 31, 20, 23, 41),\n",
      " 'price': 11.3,\n",
      " 'tip': 1.0,\n",
      " 'vendor_id': 2}\n",
      "{'distance': 0.5,\n",
      " 'drop_time': datetime.datetime(2018, 10, 31, 22, 48, 28),\n",
      " 'num_passengers': 1,\n",
      " 'pickup_time': datetime.datetime(2018, 10, 31, 22, 44, 24),\n",
      " 'price': 5.8,\n",
      " 'tip': 0.0,\n",
      " 'vendor_id': 2}\n",
      "{'distance': 1.81,\n",
      " 'drop_time': datetime.datetime(2018, 10, 31, 23, 35, 30),\n",
      " 'num_passengers': 1,\n",
      " 'pickup_time': datetime.datetime(2018, 10, 31, 23, 22, 18),\n",
      " 'price': 13.56,\n",
      " 'tip': 2.26,\n",
      " 'vendor_id': 2}\n"
     ]
    }
   ],
   "source": [
    "example(nrows=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading csv file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                          int64\n",
       "tpep_pickup_datetime     datetime64[ns]\n",
       "tpep_dropoff_datetime    datetime64[ns]\n",
       "passenger_count                   int64\n",
       "trip_distance                   float64\n",
       "RatecodeID                        int64\n",
       "store_and_fwd_flag               object\n",
       "PULocationID                      int64\n",
       "DOLocationID                      int64\n",
       "payment_type                      int64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(fileLocation, parse_dates=[1,2])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incase the file size is too big, we can use the chunk size parameter in the pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.parsers.readers.TextFileReader at 0x19102c6cd30>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.read_csv(fileLocation, parse_dates=[1,2], chunksize=1000)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all the df is stored in the textfilereader which contains the dataframe in many chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks are 0\n"
     ]
    }
   ],
   "source": [
    "total_chunks = 0\n",
    "for sub_df in dfs:\n",
    "    total_chunks += 1\n",
    "    print(sub_df.shape)\n",
    "\n",
    "print(\"Total number of chunks are\", total_chunks)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1656b90890b248568fbca2e422bd621f22b080de0a43f169e4daa3151f50a627"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
